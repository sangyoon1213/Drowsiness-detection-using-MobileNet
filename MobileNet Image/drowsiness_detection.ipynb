{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee37afb5",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740de2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193290c",
   "metadata": {},
   "source": [
    "# Displaying an image from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d4f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgSrc = \"Prediction_Testing/open eyes/s0007_00614_0_0_1_0_0_01.png\"\n",
    "img = cv2.imread(imgSrc)\n",
    "\n",
    "img_cvt = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_cvt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cvt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a327a",
   "metadata": {},
   "source": [
    "# Setting up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad33635",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(\"Prediction_Testing/\", \"close eyes\"))\n",
    "print(len(os.listdir(os.path.join(\"Prediction_Testing/\", \"close eyes\"))))\n",
    "print(len(os.listdir(os.path.join(\"Prediction_Testing/\", \"open eyes\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aed088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO EXTRACT AND TRAIN DATA LOCALLY\n",
    "Datadirectory = \"Prediction_Testing/\"\n",
    "Classes = [\"close eyes\", \"open eyes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in Classes:\n",
    "  path = os.path.join(Datadirectory, category)\n",
    "  for img in os.listdir(path):\n",
    "    img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "    backtorgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "    plt.imshow(img_array, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6943802",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "\n",
    "new_array = cv2.resize(backtorgb,(img_size, img_size))\n",
    "plt.imshow(new_array, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5690d8",
   "metadata": {},
   "source": [
    "# Converting images into an array for data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abd9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all images and converting them into an array for data and labels\n",
    "\n",
    "img_size = 224\n",
    "training_Data = []\n",
    "\n",
    "def creating_training_Data():\n",
    "  for category in Classes:\n",
    "    path = os.path.join(Datadirectory, category)\n",
    "    class_num = Classes.index(category) # 0 1 \n",
    "    for img in os.listdir(path):\n",
    "      try:\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "        backtorgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "        new_array = cv2.resize(backtorgb, (img_size, img_size))\n",
    "        training_Data.append([new_array, class_num])\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "creating_training_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training_Data)\n",
    "print(len(training_Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc741b0d",
   "metadata": {},
   "source": [
    "# Storing X and Y labels using 'Pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles all the dataset images\n",
    "random.shuffle(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72007126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dataset eligible for transfer learning\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_Data:\n",
    "  X.append(features)\n",
    "  y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the date\n",
    "X = X / 255.0; \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b244e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out, protocol=4)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out, protocol=4)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "# all labels in X and all frames are in y now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa0f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24032d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03fa6c",
   "metadata": {},
   "source": [
    "# Training & saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c410c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5458c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e95b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input = model.layers[0].input # input\n",
    "base_output = model.layers[-4].output # dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962432aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flat_layer = layers.Flatten()(base_output)\n",
    "final_output = layers.Dense(1)(Flat_layer)\n",
    "\n",
    "final_output = layers.Activation('tanh')(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.Model(inputs=base_input, outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) # Adaptive Moment Estimation (ADAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea927c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model fitting/training\n",
    "new_model.fit(X, y, epochs=6, validation_split=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('drowsiness_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296c6be",
   "metadata": {},
   "source": [
    "# Loading trained model & prediction on test image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b79ff1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('drowsiness_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "\n",
    "imgSrc = \"Prediction_Testing/s0001_02334_0_0_1_0_0_01.png\"\n",
    "# imgSrc = \"Prediction_Testing/s0001_00001_0_0_0_0_0_01.png\"\n",
    "\n",
    "img_array = cv2.imread(imgSrc, cv2.IMREAD_GRAYSCALE)\n",
    "backtorgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "new_array = cv2.resize(backtorgb, (img_size, img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab7ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = np.array(new_array).reshape(1, img_size, img_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = X_input / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = new_model.predict(X_input)\n",
    "\n",
    "# -ve -> closed eye\n",
    "# +ve -> opened eye\n",
    "print(prediction)\n",
    "\n",
    "result = \"Opened eyes detected\" if prediction > 0 else \"Closed eyes detected\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086ecb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90bfd54ebb84336800acb4e134bc1d15911d869623914c0264a346d311cc570d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
